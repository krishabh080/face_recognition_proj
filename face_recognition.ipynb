{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "92094a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the cv2 library\n",
    "import cv2\n",
    "# loading the haar case algorithm file into alg variable\n",
    "alg = \"myhaarcascade_frontalface_default.xml\"\n",
    "# passing the algorithm to OpenCV\n",
    "haar_cascade = cv2.CascadeClassifier(alg)\n",
    "# loading the image path into file_name variable\n",
    "file_name = 's2.jpg'\n",
    "# reading the image\n",
    "img = cv2.imread(file_name, 0)\n",
    "# creating a black and white version of the image\n",
    "gray_img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "# detecting the faces\n",
    "faces = haar_cascade.detectMultiScale(gray_img, scaleFactor=1.05, minNeighbors=2, minSize=(100, 100))\n",
    "# for each face detected\n",
    "for x, y, w, h in faces:\n",
    "    # crop the image to select only the face\n",
    "    cropped_image = img[y : y + h, x : x + w]\n",
    "    # loading the target image path into target_file_name variable\n",
    "    target_file_name = 's2f.jpg'\n",
    "    cv2.imwrite(\n",
    "        target_file_name,\n",
    "        cropped_image,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c60200bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the required libraries\n",
    "import numpy as np\n",
    "from imgbeddings import imgbeddings\n",
    "from PIL import Image\n",
    "# loading the face image path into file_name variable\n",
    "file_name = \"s2f.jpg\"\n",
    "# opening the image\n",
    "img = Image.open(file_name)\n",
    "# loading the `imgbeddings`\n",
    "ibed = imgbeddings()\n",
    "# calculating the embeddings\n",
    "embedding = ibed.to_embeddings(img)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99aaa9e6",
   "metadata": {},
   "outputs": [],
   "source": [
    " !psql postgres://avnadmin:AVNS_Jtef3w8Mb6i2jem6wH6@pg-1aa133ee-krishabh080-cd8e.aivencloud.com:26454/defaultdb?sslmode=require"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b262d869",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the required libraries\n",
    "import psycopg2\n",
    "conn = psycopg2.connect('postgres://avnadmin:AVNS_Jtef3w8Mb6i2jem6wH6@pg-1aa133ee-krishabh080-cd8e.aivencloud.com:26454/defaultdb?sslmode=require')\n",
    "cur = conn.cursor()\n",
    "cur.execute('INSERT INTO pictures values (%s,%s)', (file_name, embedding.tolist()))\n",
    "conn.commit()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "31a116d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "# loading the image path into file_name variable\n",
    "file_name = 'c3.jpg'\n",
    "# reading the image\n",
    "img = cv2.imread(file_name, 0)\n",
    "# creating a black and white version of the image\n",
    "gray_img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "# detecting the faces\n",
    "faces = haar_cascade.detectMultiScale(gray_img, scaleFactor=1.05, minNeighbors=2, minSize=(100, 100))\n",
    "# for each face detected in the Slack picture\n",
    "for x, y, w, h in faces:\n",
    "    # crop the image to select only the face\n",
    "    cropped_image = img[y : y + h, x : x + w]\n",
    "    \n",
    "    # Convert the NumPy array to a PIL image\n",
    "    pil_image = Image.fromarray(cropped_image)\n",
    "    \n",
    "    ibed = imgbeddings()\n",
    "    \n",
    "    # calculating the embeddings\n",
    "    slack_img_embedding = ibed.to_embeddings(pil_image)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "677a107d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the required libraries\n",
    "import numpy as np\n",
    "from imgbeddings import imgbeddings\n",
    "from PIL import Image\n",
    "# loading the face image path into file_name variable\n",
    "file_name = \"h1.jpg\"\n",
    "# opening the image\n",
    "img = Image.open(file_name)\n",
    "# loading the `imgbeddings`\n",
    "ibed = imgbeddings()\n",
    "# calculating the embeddings\n",
    "slack_img_embedding = ibed.to_embeddings(img)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "082f2a0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('r2f.jpg',)\n",
      "('s2f.jpg',)\n",
      "('r3f.jpg',)\n",
      "('r1f.jpg',)\n",
      "('s1f.jpg',)\n"
     ]
    }
   ],
   "source": [
    "conn = psycopg2.connect('postgres://avnadmin:AVNS_Jtef3w8Mb6i2jem6wH6@pg-1aa133ee-krishabh080-cd8e.aivencloud.com:26454/defaultdb?sslmode=require')\n",
    "cur = conn.cursor()\n",
    "string_rep = \"[\" + \",\".join(str(x) for x in slack_img_embedding.tolist()) + \"]\"\n",
    "cur.execute(\"SELECT picture FROM pictures ORDER BY embedding <-> %s LIMIT 5;\", (string_rep,))\n",
    "rows = cur.fetchall()\n",
    "for row in rows:\n",
    "    print(row)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b61070",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
